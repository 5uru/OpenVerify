{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-23T15:16:29.035618Z",
     "start_time": "2024-06-23T15:16:27.823162Z"
    }
   },
   "source": [
    "# read datasets/files.csv with column \"file\" and \"label\"\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('datasets/files.csv' , sep=',')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:16:29.045733Z",
     "start_time": "2024-06-23T15:16:29.037957Z"
    }
   },
   "cell_type": "code",
   "source": "df.head( )",
   "id": "c6e88a18a58d878f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                       file  label\n",
       "0  000F5AD1-B29F-4AC9-873E-CB9FC12D457D.mp4      0\n",
       "1  005CA393-E3DA-4845-A921-765A2D1091DD.mp4      0\n",
       "2  009B7423-CE0C-4D81-9F7A-DB5B283C3946.mp4      0\n",
       "3  00E2D549-34A4-488F-8402-F7CA255E8197.mp4      0\n",
       "4  00F7BED6-DD5D-48B9-A38B-6B8A9112A4BD.mp4      0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000F5AD1-B29F-4AC9-873E-CB9FC12D457D.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005CA393-E3DA-4845-A921-765A2D1091DD.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>009B7423-CE0C-4D81-9F7A-DB5B283C3946.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00E2D549-34A4-488F-8402-F7CA255E8197.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00F7BED6-DD5D-48B9-A38B-6B8A9112A4BD.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:16:29.049853Z",
     "start_time": "2024-06-23T15:16:29.046580Z"
    }
   },
   "cell_type": "code",
   "source": "df[ \"file\" ]",
   "id": "fd42d9fb32440a94",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      000F5AD1-B29F-4AC9-873E-CB9FC12D457D.mp4\n",
       "1      005CA393-E3DA-4845-A921-765A2D1091DD.mp4\n",
       "2      009B7423-CE0C-4D81-9F7A-DB5B283C3946.mp4\n",
       "3      00E2D549-34A4-488F-8402-F7CA255E8197.mp4\n",
       "4      00F7BED6-DD5D-48B9-A38B-6B8A9112A4BD.mp4\n",
       "                         ...                   \n",
       "397    FA56F667-F0E7-4E34-B5DA-8EF74137DBDD.mp4\n",
       "398    FAD22055-50B3-4D46-8055-AD212B33CEB2.mp4\n",
       "399    FC503F8E-5C19-4062-90F6-AD30F4E10B2E.mp4\n",
       "400    FCCBFBCD-C00B-4145-BB3E-679957CCEB21.mp4\n",
       "401    FF17EB94-B9A6-48E0-98E3-755CD3F0DD66.mp4\n",
       "Name: file, Length: 402, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:16:29.052902Z",
     "start_time": "2024-06-23T15:16:29.050460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df[ \"file\" ] = df[ \"file\" ].apply(lambda x : f'datasets/data/{x}')\n",
    "df[ \"label\" ] = df[ \"label\" ].apply(lambda x : \"real\" if x == 1 else 'attack')"
   ],
   "id": "5e245a34932039d2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:16:29.058016Z",
     "start_time": "2024-06-23T15:16:29.054730Z"
    }
   },
   "cell_type": "code",
   "source": "df.head( )",
   "id": "db32a56fd275f5f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                file   label\n",
       "0  datasets/data/000F5AD1-B29F-4AC9-873E-CB9FC12D...  attack\n",
       "1  datasets/data/005CA393-E3DA-4845-A921-765A2D10...  attack\n",
       "2  datasets/data/009B7423-CE0C-4D81-9F7A-DB5B283C...  attack\n",
       "3  datasets/data/00E2D549-34A4-488F-8402-F7CA255E...  attack\n",
       "4  datasets/data/00F7BED6-DD5D-48B9-A38B-6B8A9112...  attack"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datasets/data/000F5AD1-B29F-4AC9-873E-CB9FC12D...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datasets/data/005CA393-E3DA-4845-A921-765A2D10...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datasets/data/009B7423-CE0C-4D81-9F7A-DB5B283C...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datasets/data/00E2D549-34A4-488F-8402-F7CA255E...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datasets/data/00F7BED6-DD5D-48B9-A38B-6B8A9112...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:16:31.552917Z",
     "start_time": "2024-06-23T15:16:29.058509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# split the dataset into train, test and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train , test = train_test_split(df , test_size=0.2 , random_state=42)\n",
    "train , val = train_test_split(train , test_size=0.2 , random_state=42)\n"
   ],
   "id": "e86c774184de9a22",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:16:31.557071Z",
     "start_time": "2024-06-23T15:16:31.553465Z"
    }
   },
   "cell_type": "code",
   "source": "val.head(100)",
   "id": "ad2c4b21001d7541",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  file   label\n",
       "291  datasets/data/379CF6ED-B164-4E5C-ACDB-67F5E23D...    real\n",
       "179  datasets/data/517DC0E1-9BC6-499F-8AC8-2965DBDA...  attack\n",
       "206  datasets/data/5D2206AE-A1F5-470C-8352-2E7302A1...  attack\n",
       "234  datasets/data/6F3D521D-00AD-4F4B-AA8D-088494F9...  attack\n",
       "67   datasets/data/1AF5C278-9CA6-4D71-8A99-39CA08D4...  attack\n",
       "..                                                 ...     ...\n",
       "300  datasets/data/42A2E59D-0A31-4E55-A71B-7AD9898D...    real\n",
       "139  datasets/data/3FFAB8BA-91A5-41D2-B433-D36F124B...  attack\n",
       "58   datasets/data/15063135-BA45-404A-A90B-4B18E563...  attack\n",
       "205  datasets/data/5C837C74-F651-47FA-A3AD-9E46A108...  attack\n",
       "310  datasets/data/52EBE2F6-6CA4-44DC-93E9-3620CEAF...    real\n",
       "\n",
       "[65 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>datasets/data/379CF6ED-B164-4E5C-ACDB-67F5E23D...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>datasets/data/517DC0E1-9BC6-499F-8AC8-2965DBDA...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>datasets/data/5D2206AE-A1F5-470C-8352-2E7302A1...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>datasets/data/6F3D521D-00AD-4F4B-AA8D-088494F9...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>datasets/data/1AF5C278-9CA6-4D71-8A99-39CA08D4...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>datasets/data/42A2E59D-0A31-4E55-A71B-7AD9898D...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>datasets/data/3FFAB8BA-91A5-41D2-B433-D36F124B...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>datasets/data/15063135-BA45-404A-A90B-4B18E563...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>datasets/data/5C837C74-F651-47FA-A3AD-9E46A108...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>datasets/data/52EBE2F6-6CA4-44DC-93E9-3620CEAF...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:16:31.562541Z",
     "start_time": "2024-06-23T15:16:31.558372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Training set:\")\n",
    "print(train[ 'label' ].value_counts( ))\n",
    "\n",
    "print(\"\\nTesting set:\")\n",
    "print(test[ 'label' ].value_counts( ))\n",
    "\n",
    "print(\"\\nValidation set:\")\n",
    "print(val[ 'label' ].value_counts( ))"
   ],
   "id": "41218af465703559",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "label\n",
      "attack    170\n",
      "real       86\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Testing set:\n",
      "label\n",
      "attack    57\n",
      "real      24\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation set:\n",
      "label\n",
      "attack    41\n",
      "real      24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:16:31.564782Z",
     "start_time": "2024-06-23T15:16:31.563065Z"
    }
   },
   "cell_type": "code",
   "source": "class_labels = df[ 'label' ].unique( )",
   "id": "63be29901ac27fa4",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:16:31.566873Z",
     "start_time": "2024-06-23T15:16:31.565221Z"
    }
   },
   "cell_type": "code",
   "source": "class_labels",
   "id": "90bb3903e37768f6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['attack', 'real'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:16:31.569639Z",
     "start_time": "2024-06-23T15:16:31.567283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label2id = { label : i for i , label in enumerate(class_labels) }\n",
    "id2label = { i : label for label , i in label2id.items( ) }"
   ],
   "id": "91930c608b10b62c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:16:36.230765Z",
     "start_time": "2024-06-23T15:16:31.570155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import VideoMAEImageProcessor , VideoMAEForVideoClassification\n",
    "\n",
    "model_ckpt = \"MCG-NJU/videomae-base\"\n",
    "image_processor = VideoMAEImageProcessor.from_pretrained(model_ckpt)\n",
    "model = VideoMAEForVideoClassification.from_pretrained(\n",
    "        model_ckpt ,\n",
    "        label2id=label2id ,\n",
    "        id2label=id2label ,\n",
    "        ignore_mismatched_sizes=True ,  # provide this in case you're planning to fine-tune an already fine-tuned checkpoint\n",
    ")"
   ],
   "id": "9f0cfc4716b923",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathansuru/anaconda3/envs/OpenVerify/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "Some weights of VideoMAEForVideoClassification were not initialized from the model checkpoint at MCG-NJU/videomae-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:16:37.473282Z",
     "start_time": "2024-06-23T15:16:36.292288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import pytorchvideo.data\n",
    "\n"
   ],
   "id": "a799d4d962448573",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:16:37.480006Z",
     "start_time": "2024-06-23T15:16:37.473795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey ,\n",
    "    Normalize ,\n",
    "    RandomShortSideScale ,\n",
    "    RemoveKey ,\n",
    "    ShortSideScale ,\n",
    "    UniformTemporalSubsample ,\n",
    ")\n",
    "\n"
   ],
   "id": "c24c282aad7e9205",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:16:37.481919Z",
     "start_time": "2024-06-23T15:16:37.480555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision.transforms import (\n",
    "    Compose ,\n",
    "    Lambda ,\n",
    "    RandomCrop ,\n",
    "    RandomHorizontalFlip ,\n",
    "    Resize ,\n",
    ")"
   ],
   "id": "b2fcb741dd497eff",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:16:58.778074Z",
     "start_time": "2024-06-23T15:16:58.771762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean = image_processor.image_mean\n",
    "std = image_processor.image_std\n",
    "if \"shortest_edge\" in image_processor.size :\n",
    "    height = width = image_processor.size[ \"shortest_edge\" ]\n",
    "else :\n",
    "    height = image_processor.size[ \"height\" ]\n",
    "    width = image_processor.size[ \"width\" ]\n",
    "resize_to = (height , width)\n",
    "\n",
    "num_frames_to_sample = model.config.num_frames\n",
    "sample_rate = 4\n",
    "fps = 30\n",
    "clip_duration = num_frames_to_sample * sample_rate / fps"
   ],
   "id": "3ba54150447d38d5",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:18:08.106528Z",
     "start_time": "2024-06-23T15:18:08.100487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_transform = Compose(\n",
    "        [\n",
    "                ApplyTransformToKey(\n",
    "                        key=\"video\" ,\n",
    "                        transform=Compose(\n",
    "                                [\n",
    "                                        UniformTemporalSubsample(num_frames_to_sample) ,\n",
    "                                        Lambda(lambda x : x / 255.0) ,\n",
    "                                        Normalize(mean , std) ,\n",
    "                                        RandomShortSideScale(min_size=256 , max_size=320) ,\n",
    "                                        RandomCrop(resize_to) ,\n",
    "                                        RandomHorizontalFlip(p=0.5) ,\n",
    "                                ]\n",
    "                        ) ,\n",
    "                ) ,\n",
    "        ]\n",
    ")"
   ],
   "id": "380e71e66c81b561",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:19:18.325594Z",
     "start_time": "2024-06-23T15:19:18.319129Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_root_path = \"datasets/data\"",
   "id": "5dd414dfbb8cc01d",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:20:01.568960Z",
     "start_time": "2024-06-23T15:20:01.516175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "train_dataset = pytorchvideo.data.Ucf101(\n",
    "        data_path=\"datasets/data\" ,\n",
    "        clip_sampler=pytorchvideo.data.make_clip_sampler(\"random\" , clip_duration) ,\n",
    "        decode_audio=False ,\n",
    "        transform=train_transform ,\n",
    ")"
   ],
   "id": "d775d0890e14ce62",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'class_to_index' must have at least one entry to collect any samples.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m pytorchvideo\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mUcf101(\n\u001B[1;32m      4\u001B[0m         data_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatasets/data\u001B[39m\u001B[38;5;124m\"\u001B[39m ,\n\u001B[1;32m      5\u001B[0m         clip_sampler\u001B[38;5;241m=\u001B[39mpytorchvideo\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mmake_clip_sampler(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrandom\u001B[39m\u001B[38;5;124m\"\u001B[39m , clip_duration) ,\n\u001B[1;32m      6\u001B[0m         decode_audio\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m ,\n\u001B[1;32m      7\u001B[0m         transform\u001B[38;5;241m=\u001B[39mtrain_transform ,\n\u001B[1;32m      8\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/OpenVerify/lib/python3.11/site-packages/pytorchvideo/data/ucf101.py:62\u001B[0m, in \u001B[0;36mUcf101\u001B[0;34m(data_path, clip_sampler, video_sampler, transform, video_path_prefix, decode_audio, decoder)\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;124;03mA helper function to create ``LabeledVideoDataset`` object for the Ucf101 dataset.\u001B[39;00m\n\u001B[1;32m     28\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     57\u001B[0m \n\u001B[1;32m     58\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     60\u001B[0m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_log_api_usage_once(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPYTORCHVIDEO.dataset.Ucf101\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 62\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m labeled_video_dataset(\n\u001B[1;32m     63\u001B[0m     data_path,\n\u001B[1;32m     64\u001B[0m     clip_sampler,\n\u001B[1;32m     65\u001B[0m     video_sampler,\n\u001B[1;32m     66\u001B[0m     transform,\n\u001B[1;32m     67\u001B[0m     video_path_prefix,\n\u001B[1;32m     68\u001B[0m     decode_audio,\n\u001B[1;32m     69\u001B[0m     decoder,\n\u001B[1;32m     70\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/OpenVerify/lib/python3.11/site-packages/pytorchvideo/data/labeled_video_dataset.py:296\u001B[0m, in \u001B[0;36mlabeled_video_dataset\u001B[0;34m(data_path, clip_sampler, video_sampler, transform, video_path_prefix, decode_audio, decoder)\u001B[0m\n\u001B[1;32m    254\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlabeled_video_dataset\u001B[39m(\n\u001B[1;32m    255\u001B[0m     data_path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m    256\u001B[0m     clip_sampler: ClipSampler,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    261\u001B[0m     decoder: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpyav\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    262\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LabeledVideoDataset:\n\u001B[1;32m    263\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;124;03m    A helper function to create ``LabeledVideoDataset`` object for Ucf101 and Kinetics datasets.\u001B[39;00m\n\u001B[1;32m    265\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    294\u001B[0m \n\u001B[1;32m    295\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 296\u001B[0m     labeled_video_paths \u001B[38;5;241m=\u001B[39m LabeledVideoPaths\u001B[38;5;241m.\u001B[39mfrom_path(data_path)\n\u001B[1;32m    297\u001B[0m     labeled_video_paths\u001B[38;5;241m.\u001B[39mpath_prefix \u001B[38;5;241m=\u001B[39m video_path_prefix\n\u001B[1;32m    298\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m LabeledVideoDataset(\n\u001B[1;32m    299\u001B[0m         labeled_video_paths,\n\u001B[1;32m    300\u001B[0m         clip_sampler,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    304\u001B[0m         decoder\u001B[38;5;241m=\u001B[39mdecoder,\n\u001B[1;32m    305\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/OpenVerify/lib/python3.11/site-packages/pytorchvideo/data/labeled_video_paths.py:32\u001B[0m, in \u001B[0;36mLabeledVideoPaths.from_path\u001B[0;34m(cls, data_path)\u001B[0m\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m LabeledVideoPaths\u001B[38;5;241m.\u001B[39mfrom_csv(data_path)\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m g_pathmgr\u001B[38;5;241m.\u001B[39misdir(data_path):\n\u001B[0;32m---> 32\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m LabeledVideoPaths\u001B[38;5;241m.\u001B[39mfrom_directory(data_path)\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdata_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/OpenVerify/lib/python3.11/site-packages/pytorchvideo/data/labeled_video_paths.py:101\u001B[0m, in \u001B[0;36mLabeledVideoPaths.from_directory\u001B[0;34m(cls, dir_path)\u001B[0m\n\u001B[1;32m     97\u001B[0m classes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m(\n\u001B[1;32m     98\u001B[0m     (f\u001B[38;5;241m.\u001B[39mname \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m pathlib\u001B[38;5;241m.\u001B[39mPath(dir_path)\u001B[38;5;241m.\u001B[39miterdir() \u001B[38;5;28;01mif\u001B[39;00m f\u001B[38;5;241m.\u001B[39mis_dir())\n\u001B[1;32m     99\u001B[0m )\n\u001B[1;32m    100\u001B[0m class_to_idx \u001B[38;5;241m=\u001B[39m {classes[i]: i \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(classes))}\n\u001B[0;32m--> 101\u001B[0m video_paths_and_label \u001B[38;5;241m=\u001B[39m make_dataset(\n\u001B[1;32m    102\u001B[0m     dir_path, class_to_idx, extensions\u001B[38;5;241m=\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmp4\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mavi\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    103\u001B[0m )\n\u001B[1;32m    104\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[1;32m    105\u001B[0m     \u001B[38;5;28mlen\u001B[39m(video_paths_and_label) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    106\u001B[0m ), \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to load dataset from \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdir_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    107\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(video_paths_and_label)\n",
      "File \u001B[0;32m~/anaconda3/envs/OpenVerify/lib/python3.11/site-packages/torchvision/datasets/folder.py:68\u001B[0m, in \u001B[0;36mmake_dataset\u001B[0;34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001B[0m\n\u001B[1;32m     66\u001B[0m     _, class_to_idx \u001B[38;5;241m=\u001B[39m find_classes(directory)\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m class_to_idx:\n\u001B[0;32m---> 68\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclass_to_index\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m must have at least one entry to collect any samples.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     70\u001B[0m both_none \u001B[38;5;241m=\u001B[39m extensions \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m is_valid_file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m both_something \u001B[38;5;241m=\u001B[39m extensions \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m is_valid_file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: 'class_to_index' must have at least one entry to collect any samples."
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:52:54.149666Z",
     "start_time": "2024-06-23T15:52:54.082472Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8d7aaa43b2cb0229",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'collections' has no attribute 'Iterable'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 11\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdatasets\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtransforms\u001B[39;00m\n\u001B[1;32m      6\u001B[0m dataset \u001B[38;5;241m=\u001B[39m datasets\u001B[38;5;241m.\u001B[39mVideoDataset(\n\u001B[1;32m      7\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatasets/files.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m ,\n\u001B[1;32m      8\u001B[0m         transform\u001B[38;5;241m=\u001B[39mtorchvision\u001B[38;5;241m.\u001B[39mtransforms\u001B[38;5;241m.\u001B[39mCompose([\n\u001B[1;32m      9\u001B[0m                 transforms\u001B[38;5;241m.\u001B[39mVideoFilePathToTensor(max_len\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m , fps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m , padding_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlast\u001B[39m\u001B[38;5;124m'\u001B[39m) ,\n\u001B[1;32m     10\u001B[0m                 transforms\u001B[38;5;241m.\u001B[39mVideoRandomCrop([ \u001B[38;5;241m512\u001B[39m , \u001B[38;5;241m512\u001B[39m ]) ,\n\u001B[0;32m---> 11\u001B[0m                 transforms\u001B[38;5;241m.\u001B[39mVideoResize([ \u001B[38;5;241m256\u001B[39m , \u001B[38;5;241m256\u001B[39m ]) ,\n\u001B[1;32m     12\u001B[0m         ])\n\u001B[1;32m     13\u001B[0m )\n\u001B[1;32m     14\u001B[0m data_loader \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataLoader(dataset , batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m , shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m videos \u001B[38;5;129;01min\u001B[39;00m data_loader :\n",
      "File \u001B[0;32m~/PycharmProjects/OpenVerify/labs/spoofing_detection/transforms.py:210\u001B[0m, in \u001B[0;36mVideoResize.__init__\u001B[0;34m(self, size, interpolation)\u001B[0m\n\u001B[1;32m    209\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, size, interpolation\u001B[38;5;241m=\u001B[39mPIL\u001B[38;5;241m.\u001B[39mImage\u001B[38;5;241m.\u001B[39mBILINEAR):\n\u001B[0;32m--> 210\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(size, collections\u001B[38;5;241m.\u001B[39mIterable) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(size) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m    211\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msize \u001B[38;5;241m=\u001B[39m size\n\u001B[1;32m    212\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minterpolation \u001B[38;5;241m=\u001B[39m interpolation\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'collections' has no attribute 'Iterable'"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3baf1c2375204f7a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
