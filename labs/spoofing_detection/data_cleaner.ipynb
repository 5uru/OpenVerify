{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-24T13:04:22.796351Z",
     "start_time": "2024-06-24T13:04:22.329413Z"
    }
   },
   "source": [
    "# read datasets/files.csv with column \"file\" and \"label\"\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('datasets/files.csv' , sep=',')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:38:27.977013Z",
     "start_time": "2024-06-24T12:38:27.971882Z"
    }
   },
   "cell_type": "code",
   "source": "df.head( )",
   "id": "c6e88a18a58d878f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                       file  label\n",
       "0  000F5AD1-B29F-4AC9-873E-CB9FC12D457D.mp4      0\n",
       "1  005CA393-E3DA-4845-A921-765A2D1091DD.mp4      0\n",
       "2  009B7423-CE0C-4D81-9F7A-DB5B283C3946.mp4      0\n",
       "3  00E2D549-34A4-488F-8402-F7CA255E8197.mp4      0\n",
       "4  00F7BED6-DD5D-48B9-A38B-6B8A9112A4BD.mp4      0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000F5AD1-B29F-4AC9-873E-CB9FC12D457D.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005CA393-E3DA-4845-A921-765A2D1091DD.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>009B7423-CE0C-4D81-9F7A-DB5B283C3946.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00E2D549-34A4-488F-8402-F7CA255E8197.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00F7BED6-DD5D-48B9-A38B-6B8A9112A4BD.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:38:27.981029Z",
     "start_time": "2024-06-24T12:38:27.977546Z"
    }
   },
   "cell_type": "code",
   "source": "df[ \"file\" ]",
   "id": "fd42d9fb32440a94",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      000F5AD1-B29F-4AC9-873E-CB9FC12D457D.mp4\n",
       "1      005CA393-E3DA-4845-A921-765A2D1091DD.mp4\n",
       "2      009B7423-CE0C-4D81-9F7A-DB5B283C3946.mp4\n",
       "3      00E2D549-34A4-488F-8402-F7CA255E8197.mp4\n",
       "4      00F7BED6-DD5D-48B9-A38B-6B8A9112A4BD.mp4\n",
       "                         ...                   \n",
       "397    FA56F667-F0E7-4E34-B5DA-8EF74137DBDD.mp4\n",
       "398    FAD22055-50B3-4D46-8055-AD212B33CEB2.mp4\n",
       "399    FC503F8E-5C19-4062-90F6-AD30F4E10B2E.mp4\n",
       "400    FCCBFBCD-C00B-4145-BB3E-679957CCEB21.mp4\n",
       "401    FF17EB94-B9A6-48E0-98E3-755CD3F0DD66.mp4\n",
       "Name: file, Length: 402, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T13:04:26.882677Z",
     "start_time": "2024-06-24T13:04:26.877205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df[ \"file\" ] = df[ \"file\" ].apply(lambda x : f'datasets/data/{x}')\n",
    "df[ \"label\" ] = df[ \"label\" ].apply(lambda x : \"real\" if x == 1 else 'attack')"
   ],
   "id": "5e245a34932039d2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:38:27.988246Z",
     "start_time": "2024-06-24T12:38:27.985092Z"
    }
   },
   "cell_type": "code",
   "source": "df.head( )",
   "id": "db32a56fd275f5f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                file   label\n",
       "0  datasets/data/000F5AD1-B29F-4AC9-873E-CB9FC12D...  attack\n",
       "1  datasets/data/005CA393-E3DA-4845-A921-765A2D10...  attack\n",
       "2  datasets/data/009B7423-CE0C-4D81-9F7A-DB5B283C...  attack\n",
       "3  datasets/data/00E2D549-34A4-488F-8402-F7CA255E...  attack\n",
       "4  datasets/data/00F7BED6-DD5D-48B9-A38B-6B8A9112...  attack"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datasets/data/000F5AD1-B29F-4AC9-873E-CB9FC12D...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datasets/data/005CA393-E3DA-4845-A921-765A2D10...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datasets/data/009B7423-CE0C-4D81-9F7A-DB5B283C...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datasets/data/00E2D549-34A4-488F-8402-F7CA255E...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datasets/data/00F7BED6-DD5D-48B9-A38B-6B8A9112...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:38:29.559840Z",
     "start_time": "2024-06-24T12:38:28.894579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# split the dataset into train, test and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train , test = train_test_split(df , test_size=0.2 , random_state=42)\n",
    "train , val = train_test_split(train , test_size=0.2 , random_state=42)\n"
   ],
   "id": "e86c774184de9a22",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:38:30.251551Z",
     "start_time": "2024-06-24T12:38:30.241952Z"
    }
   },
   "cell_type": "code",
   "source": "val.head(100)",
   "id": "ad2c4b21001d7541",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  file   label\n",
       "291  datasets/data/379CF6ED-B164-4E5C-ACDB-67F5E23D...    real\n",
       "179  datasets/data/517DC0E1-9BC6-499F-8AC8-2965DBDA...  attack\n",
       "206  datasets/data/5D2206AE-A1F5-470C-8352-2E7302A1...  attack\n",
       "234  datasets/data/6F3D521D-00AD-4F4B-AA8D-088494F9...  attack\n",
       "67   datasets/data/1AF5C278-9CA6-4D71-8A99-39CA08D4...  attack\n",
       "..                                                 ...     ...\n",
       "300  datasets/data/42A2E59D-0A31-4E55-A71B-7AD9898D...    real\n",
       "139  datasets/data/3FFAB8BA-91A5-41D2-B433-D36F124B...  attack\n",
       "58   datasets/data/15063135-BA45-404A-A90B-4B18E563...  attack\n",
       "205  datasets/data/5C837C74-F651-47FA-A3AD-9E46A108...  attack\n",
       "310  datasets/data/52EBE2F6-6CA4-44DC-93E9-3620CEAF...    real\n",
       "\n",
       "[65 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>datasets/data/379CF6ED-B164-4E5C-ACDB-67F5E23D...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>datasets/data/517DC0E1-9BC6-499F-8AC8-2965DBDA...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>datasets/data/5D2206AE-A1F5-470C-8352-2E7302A1...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>datasets/data/6F3D521D-00AD-4F4B-AA8D-088494F9...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>datasets/data/1AF5C278-9CA6-4D71-8A99-39CA08D4...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>datasets/data/42A2E59D-0A31-4E55-A71B-7AD9898D...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>datasets/data/3FFAB8BA-91A5-41D2-B433-D36F124B...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>datasets/data/15063135-BA45-404A-A90B-4B18E563...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>datasets/data/5C837C74-F651-47FA-A3AD-9E46A108...</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>datasets/data/52EBE2F6-6CA4-44DC-93E9-3620CEAF...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:38:34.452507Z",
     "start_time": "2024-06-24T12:38:34.448140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Training set:\")\n",
    "print(train[ 'label' ].value_counts( ))\n",
    "\n",
    "print(\"\\nTesting set:\")\n",
    "print(test[ 'label' ].value_counts( ))\n",
    "\n",
    "print(\"\\nValidation set:\")\n",
    "print(val[ 'label' ].value_counts( ))"
   ],
   "id": "41218af465703559",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "label\n",
      "attack    170\n",
      "real       86\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Testing set:\n",
      "label\n",
      "attack    57\n",
      "real      24\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation set:\n",
      "label\n",
      "attack    41\n",
      "real      24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:44:46.868222Z",
     "start_time": "2024-06-24T12:44:46.797301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index , row in train.iterrows( ) :\n",
    "    # Get the file path and label\n",
    "    file_path = row[ 'file' ]\n",
    "    label = row[ 'label' ]\n",
    "\n",
    "    # Create a new directory named after the label if it doesn't exist\n",
    "    new_dir = os.path.join('datasets/data/train' , label)\n",
    "    os.makedirs(new_dir , exist_ok=True)\n",
    "\n",
    "    # Move the file to the new directory\n",
    "    new_file_path = os.path.join(new_dir , os.path.basename(file_path))\n",
    "    shutil.move(file_path , new_file_path)"
   ],
   "id": "2fe7582b76dbb0b9",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:45:33.508515Z",
     "start_time": "2024-06-24T12:45:33.478463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index , row in test.iterrows( ) :\n",
    "    # Get the file path and label\n",
    "    file_path = row[ 'file' ]\n",
    "    label = row[ 'label' ]\n",
    "\n",
    "    # Create a new directory named after the label if it doesn't exist\n",
    "    new_dir = os.path.join('datasets/data/test' , label)\n",
    "    os.makedirs(new_dir , exist_ok=True)\n",
    "\n",
    "    # Move the file to the new directory\n",
    "    new_file_path = os.path.join(new_dir , os.path.basename(file_path))\n",
    "    shutil.move(file_path , new_file_path)"
   ],
   "id": "ce4b946cb6125a89",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T12:45:52.010043Z",
     "start_time": "2024-06-24T12:45:51.987718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index , row in val.iterrows( ) :\n",
    "    # Get the file path and label\n",
    "    file_path = row[ 'file' ]\n",
    "    label = row[ 'label' ]\n",
    "\n",
    "    # Create a new directory named after the label if it doesn't exist\n",
    "    new_dir = os.path.join('datasets/data/val' , label)\n",
    "    os.makedirs(new_dir , exist_ok=True)\n",
    "\n",
    "    # Move the file to the new directory\n",
    "    new_file_path = os.path.join(new_dir , os.path.basename(file_path))\n",
    "    shutil.move(file_path , new_file_path)"
   ],
   "id": "dfb989d8b7ae1406",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T13:05:58.897292Z",
     "start_time": "2024-06-24T13:05:58.894905Z"
    }
   },
   "cell_type": "code",
   "source": "class_labels = df[ 'label' ].unique( )",
   "id": "63be29901ac27fa4",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T13:05:59.982117Z",
     "start_time": "2024-06-24T13:05:59.975425Z"
    }
   },
   "cell_type": "code",
   "source": "class_labels",
   "id": "90bb3903e37768f6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['attack', 'real'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T13:06:00.952742Z",
     "start_time": "2024-06-24T13:06:00.949800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label2id = { label : i for i , label in enumerate(class_labels) }\n",
    "id2label = { i : label for label , i in label2id.items( ) }"
   ],
   "id": "91930c608b10b62c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T13:06:04.634894Z",
     "start_time": "2024-06-24T13:06:01.619946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import VideoMAEImageProcessor , VideoMAEForVideoClassification\n",
    "\n",
    "model_ckpt = \"MCG-NJU/videomae-base\"\n",
    "image_processor = VideoMAEImageProcessor.from_pretrained(model_ckpt)\n",
    "model = VideoMAEForVideoClassification.from_pretrained(\n",
    "        model_ckpt ,\n",
    "        label2id=label2id ,\n",
    "        id2label=id2label ,\n",
    "        ignore_mismatched_sizes=True ,  # provide this in case you're planning to fine-tune an already fine-tuned checkpoint\n",
    ")"
   ],
   "id": "9f0cfc4716b923",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VideoMAEForVideoClassification were not initialized from the model checkpoint at MCG-NJU/videomae-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T13:06:04.638462Z",
     "start_time": "2024-06-24T13:06:04.636354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pytorchvideo.data\n",
    "\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey ,\n",
    "    Normalize ,\n",
    "    RandomShortSideScale ,\n",
    "    RemoveKey ,\n",
    "    ShortSideScale ,\n",
    "    UniformTemporalSubsample ,\n",
    ")\n",
    "\n",
    "from torchvision.transforms import (\n",
    "    Compose ,\n",
    "    Lambda ,\n",
    "    RandomCrop ,\n",
    "    RandomHorizontalFlip ,\n",
    "    Resize ,\n",
    ")"
   ],
   "id": "a799d4d962448573",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T13:06:04.641503Z",
     "start_time": "2024-06-24T13:06:04.639012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean = image_processor.image_mean\n",
    "std = image_processor.image_std\n",
    "if \"shortest_edge\" in image_processor.size :\n",
    "    height = width = image_processor.size[ \"shortest_edge\" ]\n",
    "else :\n",
    "    height = image_processor.size[ \"height\" ]\n",
    "    width = image_processor.size[ \"width\" ]\n",
    "resize_to = (height , width)\n",
    "\n",
    "num_frames_to_sample = model.config.num_frames\n",
    "sample_rate = 4\n",
    "fps = 30\n",
    "clip_duration = num_frames_to_sample * sample_rate / fps"
   ],
   "id": "12f6c7b00bafd37b",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T13:06:04.645076Z",
     "start_time": "2024-06-24T13:06:04.642828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_transform = Compose(\n",
    "        [\n",
    "                ApplyTransformToKey(\n",
    "                        key=\"video\" ,\n",
    "                        transform=Compose(\n",
    "                                [\n",
    "                                        UniformTemporalSubsample(num_frames_to_sample) ,\n",
    "                                        Lambda(lambda x : x / 255.0) ,\n",
    "                                        Normalize(mean , std) ,\n",
    "                                        RandomShortSideScale(min_size=256 , max_size=320) ,\n",
    "                                        RandomCrop(resize_to) ,\n",
    "                                        RandomHorizontalFlip(p=0.5) ,\n",
    "                                ]\n",
    "                        ) ,\n",
    "                ) ,\n",
    "        ]\n",
    ")"
   ],
   "id": "fc27c663ce725e12",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T13:06:05.710292Z",
     "start_time": "2024-06-24T13:06:05.694901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_root_path = \"datasets/data\"\n",
    "train_dataset = pytorchvideo.data.Ucf101(\n",
    "        data_path=os.path.join(dataset_root_path , \"train\") ,\n",
    "        clip_sampler=pytorchvideo.data.make_clip_sampler(\"random\" , clip_duration) ,\n",
    "        decode_audio=False ,\n",
    "        transform=train_transform ,\n",
    ")"
   ],
   "id": "482d7682c8c2710e",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m dataset_root_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatasets/data\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      2\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m pytorchvideo\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mUcf101(\n\u001B[0;32m----> 3\u001B[0m         data_path\u001B[38;5;241m=\u001B[39mos\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(dataset_root_path , \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m) ,\n\u001B[1;32m      4\u001B[0m         clip_sampler\u001B[38;5;241m=\u001B[39mpytorchvideo\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mmake_clip_sampler(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrandom\u001B[39m\u001B[38;5;124m\"\u001B[39m , clip_duration) ,\n\u001B[1;32m      5\u001B[0m         decode_audio\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m ,\n\u001B[1;32m      6\u001B[0m         transform\u001B[38;5;241m=\u001B[39mtrain_transform ,\n\u001B[1;32m      7\u001B[0m )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'os' is not defined"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T13:06:06.859368Z",
     "start_time": "2024-06-24T13:06:06.839150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_transform = Compose(\n",
    "        [\n",
    "                ApplyTransformToKey(\n",
    "                        key=\"video\" ,\n",
    "                        transform=Compose(\n",
    "                                [\n",
    "                                        UniformTemporalSubsample(num_frames_to_sample) ,\n",
    "                                        Lambda(lambda x : x / 255.0) ,\n",
    "                                        Normalize(mean , std) ,\n",
    "                                        Resize(resize_to) ,\n",
    "                                ]\n",
    "                        ) ,\n",
    "                ) ,\n",
    "        ]\n",
    ")\n",
    "\n",
    "val_dataset = pytorchvideo.data.Ucf101(\n",
    "        data_path=os.path.join(dataset_root_path , \"val\") ,\n",
    "        clip_sampler=pytorchvideo.data.make_clip_sampler(\"uniform\" , clip_duration) ,\n",
    "        decode_audio=False ,\n",
    "        transform=val_transform ,\n",
    ")\n",
    "\n",
    "test_dataset = pytorchvideo.data.Ucf101(\n",
    "        data_path=os.path.join(dataset_root_path , \"test\") ,\n",
    "        clip_sampler=pytorchvideo.data.make_clip_sampler(\"uniform\" , clip_duration) ,\n",
    "        decode_audio=False ,\n",
    "        transform=val_transform ,\n",
    ")"
   ],
   "id": "b4b6a5e6ccdcb3fe",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 18\u001B[0m\n\u001B[1;32m      1\u001B[0m val_transform \u001B[38;5;241m=\u001B[39m Compose(\n\u001B[1;32m      2\u001B[0m         [\n\u001B[1;32m      3\u001B[0m                 ApplyTransformToKey(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     14\u001B[0m         ]\n\u001B[1;32m     15\u001B[0m )\n\u001B[1;32m     17\u001B[0m val_dataset \u001B[38;5;241m=\u001B[39m pytorchvideo\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mUcf101(\n\u001B[0;32m---> 18\u001B[0m         data_path\u001B[38;5;241m=\u001B[39mos\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(dataset_root_path , \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m\"\u001B[39m) ,\n\u001B[1;32m     19\u001B[0m         clip_sampler\u001B[38;5;241m=\u001B[39mpytorchvideo\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mmake_clip_sampler(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muniform\u001B[39m\u001B[38;5;124m\"\u001B[39m , clip_duration) ,\n\u001B[1;32m     20\u001B[0m         decode_audio\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m ,\n\u001B[1;32m     21\u001B[0m         transform\u001B[38;5;241m=\u001B[39mval_transform ,\n\u001B[1;32m     22\u001B[0m )\n\u001B[1;32m     24\u001B[0m test_dataset \u001B[38;5;241m=\u001B[39m pytorchvideo\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mUcf101(\n\u001B[1;32m     25\u001B[0m         data_path\u001B[38;5;241m=\u001B[39mos\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(dataset_root_path , \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m) ,\n\u001B[1;32m     26\u001B[0m         clip_sampler\u001B[38;5;241m=\u001B[39mpytorchvideo\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mmake_clip_sampler(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muniform\u001B[39m\u001B[38;5;124m\"\u001B[39m , clip_duration) ,\n\u001B[1;32m     27\u001B[0m         decode_audio\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m ,\n\u001B[1;32m     28\u001B[0m         transform\u001B[38;5;241m=\u001B[39mval_transform ,\n\u001B[1;32m     29\u001B[0m )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'os' is not defined"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(train_dataset.num_videos , val_dataset.num_videos , test_dataset.num_videos)\n",
   "id": "23ac2f2acb3abee6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T13:04:56.945981Z",
     "start_time": "2024-06-24T13:04:56.922063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "def unnormalize_img(img) :\n",
    "    \"\"\"Un-normalizes the image pixels.\"\"\"\n",
    "    img = (img * std) + mean\n",
    "    img = (img * 255).astype(\"uint8\")\n",
    "    return img.clip(0 , 255)\n",
    "\n",
    "\n",
    "def create_gif(video_tensor , filename=\"sample.gif\") :\n",
    "    \"\"\"Prepares a GIF from a video tensor.\n",
    "    \n",
    "    The video tensor is expected to have the following shape:\n",
    "    (num_frames, num_channels, height, width).\n",
    "    \"\"\"\n",
    "    frames = [ ]\n",
    "    for video_frame in video_tensor :\n",
    "        frame_unnormalized = unnormalize_img(video_frame.permute(1 , 2 , 0).numpy( ))\n",
    "        frames.append(frame_unnormalized)\n",
    "    kargs = { \"duration\" : 0.25 }\n",
    "    imageio.mimsave(filename , frames , \"GIF\" , **kargs)\n",
    "    return filename\n",
    "\n",
    "\n",
    "def display_gif(video_tensor , gif_name=\"sample.gif\") :\n",
    "    \"\"\"Prepares and displays a GIF from a video tensor.\"\"\"\n",
    "    video_tensor = video_tensor.permute(1 , 0 , 2 , 3)\n",
    "    gif_filename = create_gif(video_tensor , gif_name)\n",
    "    return Image(filename=gif_filename)\n",
    "\n",
    "\n",
    "sample_video = next(iter(train_dataset))\n",
    "video_tensor = sample_video[ \"video\" ]\n",
    "display_gif(video_tensor)"
   ],
   "id": "cabad7f841c47d3b",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 35\u001B[0m\n\u001B[1;32m     31\u001B[0m     gif_filename \u001B[38;5;241m=\u001B[39m create_gif(video_tensor , gif_name)\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Image(filename\u001B[38;5;241m=\u001B[39mgif_filename)\n\u001B[0;32m---> 35\u001B[0m sample_video \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(train_dataset))\n\u001B[1;32m     36\u001B[0m video_tensor \u001B[38;5;241m=\u001B[39m sample_video[ \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvideo\u001B[39m\u001B[38;5;124m\"\u001B[39m ]\n\u001B[1;32m     37\u001B[0m display_gif(video_tensor)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3151359089dea057"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
